{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KH8MTKXdppl"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1616549931950,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "M3vLv8-EcawR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2502,
     "status": "ok",
     "timestamp": 1616549935980,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "ymx1LkyLb1PK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1616549941410,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "gdAi6CH9b1RP",
    "outputId": "7af5d918-bc87-40de-d237-23fce3fc08d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>comment_lower</th>\n",
       "      <th>has_apostrophe</th>\n",
       "      <th>has_new_line</th>\n",
       "      <th>join_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "0             0        0       0       0              0          0   \n",
       "1             0        0       0       0              0          0   \n",
       "2             0        0       0       0              0          0   \n",
       "3             0        0       0       0              0          0   \n",
       "4             0        0       0       0              0          0   \n",
       "\n",
       "                                       comment_lower  has_apostrophe  \\\n",
       "0  explanation\\nwhy the edits made under my usern...               1   \n",
       "1  d'aww! he matches this background colour i'm s...               1   \n",
       "2  hey man, i'm really not trying to edit war. it...               1   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...               1   \n",
       "4  you, sir, are my hero. any chance you remember...               1   \n",
       "\n",
       "   has_new_line                                        join_tokens  \n",
       "0             1  explanation edits made username hardcore metal...  \n",
       "1             0  aww matches background colour seemingly stuck ...  \n",
       "2             0  hey man really trying edit war guy constantly ...  \n",
       "3             1  make real suggestions improvement wondered sec...  \n",
       "4             0                      sir hero chance remember page  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'com_processed':'join_tokens'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','comment_text','comment_lower','has_apostrophe','has_new_line'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1616549943113,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "Cz7Mh7Lkb1TV",
    "outputId": "7f5cbe14-b289-4ff7-a455-ed04c3de229f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Columns: ['toxic' 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate'\n",
      " 'label_sum' 'join_tokens']\n"
     ]
    }
   ],
   "source": [
    "print (\"The Columns:\", df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1616549945282,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "WNC-epQRb1Vr",
    "outputId": "559c0088-7391-40a1-9629-da7696f77394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095881</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.052968</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.220035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294428</td>\n",
       "      <td>0.099496</td>\n",
       "      <td>0.223971</td>\n",
       "      <td>0.054660</td>\n",
       "      <td>0.216665</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.748388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159511.000000  159511.000000  159511.000000  159511.000000   \n",
       "mean        0.095881       0.009999       0.052968       0.002997   \n",
       "std         0.294428       0.099496       0.223971       0.054660   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate      label_sum  \n",
       "count  159511.000000  159511.000000  159511.000000  \n",
       "mean        0.049382       0.008808       0.220035  \n",
       "std         0.216665       0.093438       0.748388  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       6.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 3, 2, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label_sum.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1616549947183,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "c0THV5BAb1Xj",
    "outputId": "89cc5b56-e2fa-421a-8fca-cca3e6c998ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic \tunique values: [0 1]\n",
      "severe_toxic \tunique values: [0 1]\n",
      "obscene \tunique values: [0 1]\n",
      "threat \tunique values: [0 1]\n",
      "insult \tunique values: [0 1]\n",
      "identity_hate \tunique values: [0 1]\n"
     ]
    }
   ],
   "source": [
    "for col in ['toxic','severe_toxic','obscene','threat','insult','identity_hate']:\n",
    "  print (col, \"\\tunique values:\", df[col].unique() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "class_sum = [df[col].sum()/len(df) for col in target_columns]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "sns.barplot(x=target_columns, y=class_sum, ax=ax)\n",
    "ax.set_xticklabels(target_columns, fontsize='x-large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "0      0             0        0       0       0              0          0   \n",
       "1      0             0        0       0       0              0          0   \n",
       "2      0             0        0       0       0              0          0   \n",
       "3      0             0        0       0       0              0          0   \n",
       "4      0             0        0       0       0              0          0   \n",
       "\n",
       "                                         join_tokens  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww matches background colour seemingly stuck ...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestions improvement wondered sec...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e26f40b5cdb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_now\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_now' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_columns:\n",
    "    print (col, df[col].sum()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_metric(df, target_columns):\n",
    "    label_counts = np.array([df[col].sum() for col in target_columns])\n",
    "    IRpL = np.max(label_counts)/label_counts\n",
    "    meanIR = np.sum(IRpL)/len(IRpL)\n",
    "    return meanIR\n",
    "\n",
    "print('mean imbalance ratio (smaller is better):', imbalance_metric(df, target_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data to minimize imbalance ratio\n",
    "\n",
    "sample_per_label = 500 # we can play with this number, larger number means more imbalance\n",
    "\n",
    "counts = {'toxic':0, 'severe_toxic':0, 'obscene':0, 'threat':0, 'insult':0, 'identity_hate':0}\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for label in target_columns:\n",
    "    sample_to_add = np.max([sample_per_label - counts[label], 0])\n",
    "    \n",
    "    if sample_to_add <= 0: continue\n",
    "    \n",
    "    s = df[df[label] == 1].sample(n=np.min([sample_to_add, df[label].sum()]))\n",
    "    df.drop(s.index, inplace=True)\n",
    "    \n",
    "    new_df = new_df.append(s, ignore_index=True)\n",
    "    \n",
    "    # count labels\n",
    "    for col in target_columns:\n",
    "        counts[col] += s[col].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_columns:\n",
    "    print (col, new_df[col].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "class_sum = [new_df[col].sum()/len(df) for col in target_columns]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "sns.barplot(x=target_columns, y=class_sum, ax=ax)\n",
    "ax.set_xticklabels(target_columns, fontsize='x-large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean imbalance ratio (smaller is better):', imbalance_metric(new_df, target_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "df = new_df\n",
    "del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: tokens to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "df['tokens'] = df['comment_text'].str.lower().apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedStopWords = stopwords.words(\"english\")\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in cachedStopWords]\n",
    "\n",
    "df['tokens_nostop'] = df['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['join_tokens'] = df['tokens_nostop'].apply(join_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','comment_text'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(df.join_tokens.to_list()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many basis words. Use PCA to cut them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "#pca_pipe = Pipeline([('scale', StandardScaler()), ('pca', PCA())])\n",
    "\n",
    "#pca_pipe.fit(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams_matrix = bigrams.fit_transform(df.join_tokens.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = bigrams.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.choices(names, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(bigrams_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df.join_tokens.to_list()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['join_tokens'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test with stratify\n",
    "\n",
    "now just for tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(tfidf_matrix, df[target_columns].to_numpy(), test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(Counter(combination for row in get_combination_wise_output_matrix(y_train, order=1) for combination in row))\n",
    "\n",
    "{k: v / total for total in (sum(a.values()),) for k, v in a.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(Counter(combination for row in get_combination_wise_output_matrix(y_test, order=1) for combination in row))\n",
    "\n",
    "{k: v / total for total in (sum(a.values()),) for k, v in a.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling 0 versus 1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "0      0             0        0       0       0              0          0   \n",
       "1      0             0        0       0       0              0          0   \n",
       "2      0             0        0       0       0              0          0   \n",
       "3      0             0        0       0       0              0          0   \n",
       "4      0             0        0       0       0              0          0   \n",
       "\n",
       "                                         join_tokens  negative_comments  \n",
       "0  explanation edits made username hardcore metal...                  0  \n",
       "1  aww matches background colour seemingly stuck ...                  0  \n",
       "2  hey man really trying edit war guy constantly ...                  0  \n",
       "3  make real suggestions improvement wondered sec...                  0  \n",
       "4                      sir hero chance remember page                  0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary(inp):\n",
    "    if inp == 0: out = 0\n",
    "    else: out = 1\n",
    "    return out\n",
    "\n",
    "df['negative_comments'] = df['label_sum'].apply(binary)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.negative_comments.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting into training and test set with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_0 = int(0.2 * len(df[df.negative_comments == 0]))\n",
    "test_size_1 = int(0.2 * len(df[df.negative_comments == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_0 = df[df.negative_comments == 0].sample(n=test_size_0, random_state=101)\n",
    "df_test_1 = df[df.negative_comments == 1].sample(n=test_size_1, random_state=101)\n",
    "df_test   = df_test_0.append(df_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internet media shreveport tag placed internet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes disqualifications baseless ever supported ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ref go onto tube type tna video game angle v s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks sorry seen previous versions good faith...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113955</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>announced playstation kingdom hearts iii please</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "26349       0             0        0       0       0              0   \n",
       "13063       0             0        0       0       0              0   \n",
       "119707      0             0        0       0       0              0   \n",
       "41466       0             0        0       0       0              0   \n",
       "113955      0             0        0       0       0              0   \n",
       "\n",
       "        label_sum                                        join_tokens  \\\n",
       "26349           0  internet media shreveport tag placed internet ...   \n",
       "13063           0  yes disqualifications baseless ever supported ...   \n",
       "119707          0  ref go onto tube type tna video game angle v s...   \n",
       "41466           0  thanks sorry seen previous versions good faith...   \n",
       "113955          0    announced playstation kingdom hearts iii please   \n",
       "\n",
       "        negative_comments  \n",
       "26349                   0  \n",
       "13063                   0  \n",
       "119707                  0  \n",
       "41466                   0  \n",
       "113955                  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "1      0             0        0       0       0              0          0   \n",
       "2      0             0        0       0       0              0          0   \n",
       "3      0             0        0       0       0              0          0   \n",
       "4      0             0        0       0       0              0          0   \n",
       "6      1             1        1       0       1              0          4   \n",
       "\n",
       "                                         join_tokens  negative_comments  \n",
       "1  aww matches background colour seemingly stuck ...                  0  \n",
       "2  hey man really trying edit war guy constantly ...                  0  \n",
       "3  make real suggestions improvement wondered sec...                  0  \n",
       "4                      sir hero chance remember page                  0  \n",
       "6                        cocksucker piss around work                  1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df, df_test]).drop_duplicates(keep=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10235261335137932"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.negative_comments.sum()/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10171776064196603"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.negative_comments.sum()/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df_test_0\n",
    "del df_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_train = vectorizer.fit_transform(df_train.join_tokens.to_list()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logres = LogisticRegressionCV(cv=3, scoring='recall')\n",
    "\n",
    "logres.fit(tfidf_train, df_train['negative_comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy per label')\n",
    "for i in range(len(target_columns)):\n",
    "    clf.fit(X_train, y_train[:,i])\n",
    "    pred = clf.predict(X_test)\n",
    "    print(target_columns[i], accuracy_score(y_test[:,i], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = MultiOutputClassifier(LogisticRegression())\n",
    "mlc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = multilabel_confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_columns)):\n",
    "    print(target_columns[i], 'accuracy:', (mcm[i,0,0]+mcm[i,1,1])/np.sum(mcm[i]),\n",
    "          'precision:', mcm[i,1,1]/(mcm[i,1,1]+mcm[i,0,1]),\n",
    "          'recall:', mcm[i,1,1]/(mcm[i,1,1]+mcm[i,1,0]))\n",
    "    disp = ConfusionMatrixDisplay(mcm[i])\n",
    "    disp.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
    "# Accuracy for multilabel classifier\n",
    "def Accuracy(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    return temp / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match_ratio(y_true, y_pred):\n",
    "    return np.all(y_pred == y_true, axis=1).mean()\n",
    "\n",
    "exact_match_ratio(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred) # is the exact match ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(n_features, n_output, n_layers=1, n_nodes=10, activ_func='relu', dropout_rate=0.):\n",
    "    ''' Building neural network model '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation=activ_func, use_bias=True, input_shape=(n_features,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(n_nodes, activation=activ_func, use_bias=True))\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate, input_shape=(n_nodes,)))\n",
    "    model.add(Dense(n_output, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_network(X, y, n_output, n_layers=1, n_nodes=10, activ_func='relu', dropout_rate=0., epochs=10):\n",
    "    # Building neural network model\n",
    "    n_features = np.shape(X)[1]\n",
    "    model = build_network(n_features, n_output, n_layers, n_nodes, activ_func, dropout_rate)\n",
    "    # Compiling model\n",
    "    early_stopping_monitor = EarlyStopping(patience=5)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[binary_accuracy])\n",
    "    # Fitting model\n",
    "    history = model.fit(X, y,\n",
    "                        validation_split=0.2, epochs=epochs,\n",
    "                        shuffle=True, callbacks=[early_stopping_monitor])\n",
    "    #model.save('neuralnetwork.h5')\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = fit_network(X_train, y_train, n_output=y_train.shape[1], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_ratio(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'], label='training')\n",
    "plt.plot(history.history['val_binary_accuracy'], label='validation')\n",
    "plt.xlabel('epochs', fontsize=15)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as ppb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(inp):\n",
    "    return tokenizer.encode(inp, max_length=512, truncation=True)\n",
    "\n",
    "df['bert_tokens'] = df['tokens_nostop'].apply(make_tokens)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['bert_tokens'].to_numpy()\n",
    "\n",
    "## This goes through and finds the longest tokenized sequence\n",
    "max_len = 0\n",
    "for i in tokenized:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "## This adds the correct number of 0s to the end of the shorter sequences\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized])\n",
    "print(np.shape(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We now convert padded and attention_mask\n",
    "## into tensors\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "## We get embeddings in the same way, but now we add\n",
    "## the attention_mask argument\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = bert_model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = last_hidden_states[0].numpy()\n",
    "#y = df['coding'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('last_hidden_states.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "g01_data_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
