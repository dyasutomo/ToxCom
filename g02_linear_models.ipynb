{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KH8MTKXdppl"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1616549931950,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "M3vLv8-EcawR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "data_dir='./dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2502,
     "status": "ok",
     "timestamp": 1616549935980,
     "user": {
      "displayName": "Ghanashyam Khanal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNFB_3XwLB8BEW17lVypQ54QKRq7KnQZVd8M-QU9c=s64",
      "userId": "16880718905978803098"
     },
     "user_tz": 240
    },
    "id": "ymx1LkyLb1PK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>comment_lower</th>\n",
       "      <th>has_apostrophe</th>\n",
       "      <th>has_new_line</th>\n",
       "      <th>com_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "0             0        0       0       0              0          0   \n",
       "1             0        0       0       0              0          0   \n",
       "\n",
       "                                       comment_lower  has_apostrophe  \\\n",
       "0  explanation\\nwhy the edits made under my usern...               1   \n",
       "1  d'aww! he matches this background colour i'm s...               1   \n",
       "\n",
       "   has_new_line                                      com_processed  \n",
       "0             1  explanation edits made username hardcore metal...  \n",
       "1             0  aww matches background colour seemingly stuck ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir+'df_processed.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def prepare_TFIDF(df, col):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state = 8848)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "    vectorizer.fit_transform(df_train[col].values)\n",
    "    \n",
    "    X_train = vectorizer.transform(df_train[col].values)\n",
    "    X_test  = vectorizer.transform(df_test[col].values)\n",
    "    \n",
    "    y_train = df_train[target_columns].values\n",
    "    y_test  = df_test[target_columns].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, vectorizer\n",
    "\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf, vectorizer= prepare_TFIDF(df, \"com_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape:  (127608, 147278)\n",
      "y_train Shape:  (127608, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape: \", X_train_tf.toarray().shape)\n",
    "print(\"y_train Shape: \", y_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model(X_train, y_train, X_test, multi=False):\n",
    "    if multi:\n",
    "        model = MultiOutputClassifier(LogisticRegression(penalty='l2', C=1.0, max_iter=500))\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_labs = model.predict(X_test)\n",
    "        #y_pred_scores = model.decision_function(X_test)\n",
    "    else:\n",
    "        model = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1.0, max_iter=500))\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_labs = model.predict(X_test)\n",
    "\n",
    "    return model, y_pred_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR, y_pred_labs =  LR_model(X_train_tf, y_train_tf, X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    acc        = 100*accuracy_score(y_val, predicted)\n",
    "    f1_micro   = 100*f1_score(y_val, predicted, average='micro')\n",
    "    avg_prec_micro = 100*average_precision_score(y_val, predicted, average='micro')\n",
    "    roc_auc    = 100*roc_auc_score(y_val, predicted)\n",
    "    \n",
    "    print (\"Accuracy \\t= %1.2f \\nF1_micro\\t= %1.2f\" %(acc, f1_micro))\n",
    "    print (\"Avg Prec micro\\t= %1.2f \\nROC_AUC score\\t= %1.2f\" % ( avg_prec_micro, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with TFIDF features\n",
      "Accuracy \t= 92.01 \n",
      "F1_micro\t= 68.00\n",
      "Avg Prec micro\t= 50.55 \n",
      "ROC_AUC score\t= 68.61\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Regression with TFIDF features\")\n",
    "print_evaluation_scores(y_test_tf, y_pred_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR_multi, y_pred_labs_multi =  LR_model(X_train_tf, y_train_tf, X_test_tf, multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with TFIDF features (using MultiOutputClassifier)\n",
      "Accuracy \t= 92.01 \n",
      "F1_micro\t= 68.00\n",
      "Avg Prec micro\t= 50.55 \n",
      "ROC_AUC score\t= 68.61\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Regression with TFIDF features (using MultiOutputClassifier)\")\n",
    "print_evaluation_scores(y_test_tf, y_pred_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def prepare_BOW(df, col):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state = 8848)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit_transform(df_train[col].values)\n",
    "    \n",
    "    X_train = vectorizer.transform(df_train[col].values)\n",
    "    X_test  = vectorizer.transform(df_test[col].values)\n",
    "    \n",
    "    y_train = df_train[target_columns].values\n",
    "    y_test  = df_test[target_columns].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, vectorizer\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow, count_vectorizer= prepare_BOW(df, \"com_processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_LR_bow, y_pred_labs_bow, y_pred_scores_bow =  LR_model(X_train_bow,\n",
    "#                                                             y_train_bow,\n",
    "#                                                             X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR on the BOW data was too much to train. It failed. even after setting the max_iter=1000 the model didn't run.\n",
    "\n",
    "So Use PCA to convert the data to a smaller dimensional matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# pca_pipe = Pipeline([('scale',StandardScaler(with_mean=False)),\n",
    "#                          ('pca',PCA())])\n",
    "\n",
    "# pca_pipe.fit(X_train_tf)\n",
    "\n",
    "# #pca = PCA(n_components = 10)\n",
    "# #pca.fit(X_train_tf)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components = n_comp)\n",
    "# pca.fit(train_tfidf)\n",
    "# X_train = pca.transform(train_tfidf)\n",
    "# X_test = pca.transform(test_tfidf)\n",
    "\n",
    "# pca = PCA(n_components=200)\n",
    "\n",
    "# pca.fit(X[X.columns[1:]])\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "\n",
    "# plt.plot(range(1,201),\n",
    "#         np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# plt.xlabel(\"PCA Component\", fontsize=16)\n",
    "# plt.ylabel(\"Cumulative Variance Explained\", fontsize=16)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "g01_data_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
