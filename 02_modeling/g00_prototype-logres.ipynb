{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/df_processed.csv')\n",
    "df.drop(['id','comment_text','comment_lower','has_apostrophe','has_new_line'], axis=1, inplace=True)\n",
    "df.rename(columns={'com_processed':'join_tokens'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations well use tools well talk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "5      0             0        0       0       0              0          0   \n",
       "6      1             1        1       0       1              0          4   \n",
       "7      0             0        0       0       0              0          0   \n",
       "\n",
       "                                         join_tokens  negative_comments  \n",
       "5           congratulations well use tools well talk                  0  \n",
       "6                        cocksucker piss around work                  1  \n",
       "7  vandalism matt shirvington article reverted pl...                  0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negative_comments'] = df['label_sum'].apply(lambda x:int(x>0))\n",
    "df[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "0      0             0        0       0       0              0          0   \n",
       "1      0             0        0       0       0              0          0   \n",
       "2      0             0        0       0       0              0          0   \n",
       "3      0             0        0       0       0              0          0   \n",
       "4      0             0        0       0       0              0          0   \n",
       "\n",
       "                                         join_tokens  negative_comments  \n",
       "0  explanation edits made username hardcore metal...                  0  \n",
       "1  aww matches background colour seemingly stuck ...                  0  \n",
       "2  hey man really trying edit war guy constantly ...                  0  \n",
       "3  make real suggestions improvement wondered sec...                  0  \n",
       "4                      sir hero chance remember page                  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary(inp):\n",
    "    if inp == 0: out = 0\n",
    "    else: out = 1\n",
    "    return out\n",
    "\n",
    "df['negative_comments'] = df['label_sum'].apply(binary)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "      <td>159511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095881</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.052968</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.220035</td>\n",
       "      <td>0.101717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294428</td>\n",
       "      <td>0.099496</td>\n",
       "      <td>0.223971</td>\n",
       "      <td>0.054660</td>\n",
       "      <td>0.216665</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.748388</td>\n",
       "      <td>0.302277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159511.000000  159511.000000  159511.000000  159511.000000   \n",
       "mean        0.095881       0.009999       0.052968       0.002997   \n",
       "std         0.294428       0.099496       0.223971       0.054660   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate      label_sum  negative_comments  \n",
       "count  159511.000000  159511.000000  159511.000000      159511.000000  \n",
       "mean        0.049382       0.008808       0.220035           0.101717  \n",
       "std         0.216665       0.093438       0.748388           0.302277  \n",
       "min         0.000000       0.000000       0.000000           0.000000  \n",
       "25%         0.000000       0.000000       0.000000           0.000000  \n",
       "50%         0.000000       0.000000       0.000000           0.000000  \n",
       "75%         0.000000       0.000000       0.000000           0.000000  \n",
       "max         1.000000       1.000000       6.000000           1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "class_sum = [df[col].sum()/len(df) for col in target_columns]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "sns.barplot(x=target_columns, y=class_sum, ax=ax)\n",
    "ax.set_xticklabels(target_columns, fontsize='x-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling for prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(frac=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into train and test set with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_0 = int(0.2 * len(df[df.negative_comments == 0]))\n",
    "test_size_1 = int(0.2 * len(df[df.negative_comments == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internet media shreveport tag placed internet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes disqualifications baseless ever supported ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ref go onto tube type tna video game angle v s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks sorry seen previous versions good faith...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113955</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>announced playstation kingdom hearts iii please</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "26349       0             0        0       0       0              0   \n",
       "13063       0             0        0       0       0              0   \n",
       "119707      0             0        0       0       0              0   \n",
       "41466       0             0        0       0       0              0   \n",
       "113955      0             0        0       0       0              0   \n",
       "\n",
       "        label_sum                                        join_tokens  \\\n",
       "26349           0  internet media shreveport tag placed internet ...   \n",
       "13063           0  yes disqualifications baseless ever supported ...   \n",
       "119707          0  ref go onto tube type tna video game angle v s...   \n",
       "41466           0  thanks sorry seen previous versions good faith...   \n",
       "113955          0    announced playstation kingdom hearts iii please   \n",
       "\n",
       "        negative_comments  \n",
       "26349                   0  \n",
       "13063                   0  \n",
       "119707                  0  \n",
       "41466                   0  \n",
       "113955                  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_0 = df[df.negative_comments == 0].sample(n=test_size_0, random_state=101)\n",
    "df_test_1 = df[df.negative_comments == 1].sample(n=test_size_1, random_state=101)\n",
    "df_test   = df_test_0.append(df_test_1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>join_tokens</th>\n",
       "      <th>negative_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  label_sum  \\\n",
       "1      0             0        0       0       0              0          0   \n",
       "2      0             0        0       0       0              0          0   \n",
       "3      0             0        0       0       0              0          0   \n",
       "4      0             0        0       0       0              0          0   \n",
       "6      1             1        1       0       1              0          4   \n",
       "\n",
       "                                         join_tokens  negative_comments  \n",
       "1  aww matches background colour seemingly stuck ...                  0  \n",
       "2  hey man really trying edit war guy constantly ...                  0  \n",
       "3  make real suggestions improvement wondered sec...                  0  \n",
       "4                      sir hero chance remember page                  0  \n",
       "6                        cocksucker piss around work                  1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df, df_test]).drop_duplicates(keep=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10235261335137932"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.negative_comments.sum()/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10171776064196603"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.negative_comments.sum()/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df_test_0\n",
    "del df_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "\n",
    "tfidf_train = vectorizer.fit_transform(df_train.join_tokens.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = vectorizer.transform(df_test.join_tokens.values).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap metrics for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_binary_precision = []\n",
    "recap_binary_recall    = []\n",
    "recap_mean_precision   = []\n",
    "recap_mean_recall      = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: Direct multilabel classification with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, make_scorer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_metrics(clf, X, y):\n",
    "    pred = clf.predict(X)\n",
    "    prec, rec, fs, _ = precision_recall_fscore_support(y, pred)\n",
    "    print('mean precision: %.2f' % np.mean(prec))\n",
    "    print('mean recall: %.2f' % np.mean(rec))\n",
    "    print('mean f-score: %.2f' % np.mean(fs))\n",
    "    return pred, np.mean(prec), np.mean(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlc_base = MultiOutputClassifier(LogisticRegression())\n",
    "mlc_base.fit(tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data set\n",
      "mean precision: 0.82\n",
      "mean recall: 0.39\n",
      "mean f-score: 0.51\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for training data set')\n",
    "y_pred_train, prec_train, rec_train = mean_metrics(mlc_base, tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for test data set\n",
      "mean precision: 0.75\n",
      "mean recall: 0.39\n",
      "mean f-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for test data set')\n",
    "y_pred_test, prec_test, rec_test = mean_metrics(mlc_base, tfidf_test, df_test[target_columns])\n",
    "recap_mean_precision.append(prec_test)\n",
    "recap_mean_recall.append(rec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is metric to assess how good we can capture negative comments, irrespective of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_metric(y_true, y_pred):\n",
    "    pred_binary = np.array([1 if x > 0 else 0 for x in y_pred.sum(axis=1)])\n",
    "    prec, rec, fs, _ = precision_recall_fscore_support(df_test['negative_comments'], pred_binary)\n",
    "    print('precision: %.2f' % prec[1])\n",
    "    print('recall: %.2f' % rec[1])\n",
    "    print('f-score: %.2f' % fs[1])\n",
    "    return pred_binary, prec[1], rec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.95\n",
      "recall: 0.58\n",
      "f-score: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "pred_binary, prec_binary, rec_binary = binary_metric(df_test['negative_comments'], y_pred_test)\n",
    "recap_binary_precision.append(prec_binary)\n",
    "recap_binary_recall.append(rec_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgraded model (1): Baseline model + CV + Balanced weight in loss function + f-score optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=GridSearchCV(cv=3,\n",
       "                                             estimator=LogisticRegression(class_weight='balance'),\n",
       "                                             n_jobs=-1, param_grid={},\n",
       "                                             scoring=make_scorer(f1_score, average=micro)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(f1_score, average='micro')\n",
    "\n",
    "lr = LogisticRegression(class_weight='balance')\n",
    "\n",
    "gcv = GridSearchCV(estimator = lr,\n",
    "                   param_grid = {},\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "mlc_1 = MultiOutputClassifier(gcv)\n",
    "\n",
    "mlc_1.fit(tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data set\n",
      "mean precision: 0.82\n",
      "mean recall: 0.39\n",
      "mean f-score: 0.51\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for training data set')\n",
    "y_pred_train, prec_train, rec_train = mean_metrics(mlc_1, tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for test data set\n",
      "mean precision: 0.75\n",
      "mean recall: 0.39\n",
      "mean f-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for test data set')\n",
    "y_pred_test, prec_test, rec_test = mean_metrics(mlc_1, tfidf_test, df_test[target_columns])\n",
    "recap_mean_precision.append(prec_test)\n",
    "recap_mean_recall.append(rec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.95\n",
      "recall: 0.58\n",
      "f-score: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "pred_binary, prec_binary, rec_binary = binary_metric(df_test['negative_comments'], y_pred_test)\n",
    "recap_binary_precision.append(prec_binary)\n",
    "recap_binary_recall.append(rec_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgraded model (2): Model 1 + grid search for class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=GridSearchCV(cv=3,\n",
       "                                             estimator=LogisticRegression(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_grid={'class_weight': [{0: 0.05,\n",
       "                                                                           1: 0.95},\n",
       "                                                                          {0: 0.1,\n",
       "                                                                           1: 0.9},\n",
       "                                                                          {0: 0.15,\n",
       "                                                                           1: 0.85},\n",
       "                                                                          {0: 0.2,\n",
       "                                                                           1: 0.8},\n",
       "                                                                          {0: 0.25,\n",
       "                                                                           1: 0.75}]},\n",
       "                                             scoring=make_scorer(f1_score, average=micro)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(f1_score, average='micro')\n",
    "\n",
    "weights = [0.05,0.10,0.15,0.20,0.25]\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "gcv = GridSearchCV(estimator = lr,\n",
    "                   param_grid = param_grid,\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "mlc_2 = MultiOutputClassifier(gcv)\n",
    "\n",
    "mlc_2.fit(tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data set\n",
      "mean precision: 0.71\n",
      "mean recall: 0.52\n",
      "mean f-score: 0.58\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for training data set')\n",
    "y_pred_train, prec_train, rec_train = mean_metrics(mlc_2, tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for test data set\n",
      "mean precision: 0.65\n",
      "mean recall: 0.49\n",
      "mean f-score: 0.55\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for test data set')\n",
    "y_pred_test, prec_test, rec_test = mean_metrics(mlc_2, tfidf_test, df_test[target_columns])\n",
    "recap_mean_precision.append(prec_test)\n",
    "recap_mean_recall.append(rec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.87\n",
      "recall: 0.68\n",
      "f-score: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "pred_binary, prec_binary, rec_binary = binary_metric(df_test['negative_comments'], y_pred_test)\n",
    "recap_binary_precision.append(prec_binary)\n",
    "recap_binary_recall.append(rec_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgraded model (3): Model 2 + hyperparameter tuning for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dutomo/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dutomo/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dutomo/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dutomo/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=GridSearchCV(cv=3,\n",
       "                                             estimator=LogisticRegression(),\n",
       "                                             n_jobs=-1,\n",
       "                                             param_grid={'C': [1, 10, 100],\n",
       "                                                         'class_weight': [{0: 0.05,\n",
       "                                                                           1: 0.95},\n",
       "                                                                          {0: 0.1,\n",
       "                                                                           1: 0.9},\n",
       "                                                                          {0: 0.15,\n",
       "                                                                           1: 0.85},\n",
       "                                                                          {0: 0.2,\n",
       "                                                                           1: 0.8},\n",
       "                                                                          {0: 0.25,\n",
       "                                                                           1: 0.75}]},\n",
       "                                             scoring=make_scorer(f1_score, average=micro)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(f1_score, average='micro')\n",
    "\n",
    "weights = [0.05,0.10,0.15,0.20,0.25]\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights],\n",
    "              'C': [1, 10, 100]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "gcv = GridSearchCV(estimator = lr,\n",
    "                   param_grid = param_grid,\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "mlc_3 = MultiOutputClassifier(gcv)\n",
    "\n",
    "mlc_3.fit(tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for training data set\n",
      "mean precision: 0.81\n",
      "mean recall: 0.82\n",
      "mean f-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for training data set')\n",
    "y_pred_train, prec_train, rec_train = mean_metrics(mlc_3, tfidf_train, df_train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for test data set\n",
      "mean precision: 0.63\n",
      "mean recall: 0.56\n",
      "mean f-score: 0.58\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for test data set')\n",
    "y_pred_test, prec_test, rec_test = mean_metrics(mlc_3, tfidf_test, df_test[target_columns])\n",
    "recap_mean_precision.append(prec_test)\n",
    "recap_mean_recall.append(rec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.83\n",
      "recall: 0.75\n",
      "f-score: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "pred_binary, prec_binary, rec_binary = binary_metric(df_test['negative_comments'], y_pred_test)\n",
    "recap_binary_precision.append(prec_binary)\n",
    "recap_binary_recall.append(rec_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked model: binary classification followed by multilables classification with CV + balanced weight + scoring optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 0.05, 1: 0.95}, {0: 0.1, 1: 0.9},\n",
       "                                          {0: 0.15, 1: 0.85}, {0: 0.2, 1: 0.8},\n",
       "                                          {0: 0.25, 1: 0.75}]},\n",
       "             scoring=make_scorer(recall_score, average=binary))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(recall_score, average='binary')\n",
    "\n",
    "weights = [0.05,0.10,0.15,0.20,0.25]\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "gcv_recall = GridSearchCV(estimator = lr,\n",
    "                   param_grid = param_grid,\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "gcv_recall.fit(tfidf_train, df_train['negative_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.38\n",
      "recall: 0.94\n",
      "f-score: 0.54\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = gcv_recall.predict(tfidf_test)\n",
    "print('Metric for binary class 1')\n",
    "prec, rec, fs, _ = precision_recall_fscore_support(df_test['negative_comments'], y_pred_test)\n",
    "print('precision: %.2f' % prec[1])\n",
    "print('recall: %.2f' % rec[1])\n",
    "print('f-score: %.2f' % fs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on precision for those predicted as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 0.05, 1: 0.95}, {0: 0.1, 1: 0.9},\n",
       "                                          {0: 0.15, 1: 0.85}, {0: 0.2, 1: 0.8},\n",
       "                                          {0: 0.25, 1: 0.75}]},\n",
       "             scoring=make_scorer(f1_score, average=binary))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(f1_score, average='binary')\n",
    "\n",
    "weights = [0.05,0.10,0.15,0.20,0.25]\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "gcv_fs = GridSearchCV(estimator = lr,\n",
    "                   param_grid = param_grid,\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "gcv_fs.fit(tfidf_train, df_train['negative_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.80\n",
      "recall: 0.79\n",
      "f-score: 0.80\n"
     ]
    }
   ],
   "source": [
    "negative_index = np.where(y_pred_test == 1)\n",
    "y_pred_fs = gcv_fs.predict(tfidf_test[negative_index])\n",
    "print('Metric for binary class 1')\n",
    "prec, rec, fs, _ = precision_recall_fscore_support(df_test['negative_comments'].to_numpy()[negative_index],\n",
    "                                                   y_pred_fs)\n",
    "print('precision: %.2f' % prec[1])\n",
    "print('recall: %.2f' % rec[1])\n",
    "print('f-score: %.2f' % fs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred = []\n",
    "j = 0\n",
    "for i in range(len(y_pred_test)):\n",
    "    if y_pred_test[i] == 1:\n",
    "        comb_pred.append(y_pred_fs[j])\n",
    "        j += 1\n",
    "    else:\n",
    "        comb_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.80\n",
      "recall: 0.74\n",
      "f-score: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "prec, rec, fs, _ = precision_recall_fscore_support(df_test['negative_comments'].to_numpy(), comb_pred)\n",
    "print('precision: %.2f' % prec[1])\n",
    "print('recall: %.2f' % rec[1])\n",
    "print('f-score: %.2f' % fs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel classification for those with class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=GridSearchCV(cv=3,\n",
       "                                             estimator=LogisticRegression(class_weight='balance'),\n",
       "                                             n_jobs=-1, param_grid={},\n",
       "                                             scoring=make_scorer(f1_score, average=micro)))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_score = make_scorer(f1_score, average='micro')\n",
    "\n",
    "lr = LogisticRegression(class_weight='balance')\n",
    "\n",
    "gcv = GridSearchCV(estimator = lr,\n",
    "                   param_grid = {},\n",
    "                   cv = 3,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = custom_score,\n",
    "                   verbose = 0)\n",
    "\n",
    "mlc_stack = MultiOutputClassifier(gcv)\n",
    "\n",
    "mlc_stack.fit(tfidf_train, df_train[target_columns].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_index = np.where(np.array(comb_pred) == 1)\n",
    "pred = mlc_stack.predict(tfidf_test[negative_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.93016194, 0.5408805 , 0.91440678, 0.71428571, 0.8321608 ,\n",
       "        0.59459459]),\n",
       " array([0.79258301, 0.27831715, 0.69838188, 0.18518519, 0.58932384,\n",
       "        0.18181818]),\n",
       " array([0.85587893, 0.36752137, 0.79192661, 0.29411765, 0.69      ,\n",
       "        0.27848101]),\n",
       " array([2319,  309, 1545,   81, 1405,  242]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prec, rec, fs, _ = \n",
    "precision_recall_fscore_support(df_test[target_columns].to_numpy()[negative_index], pred)\n",
    "#print('mean precision:', np.mean(prec))\n",
    "#print('mean recall:', np.mean(rec))\n",
    "#print('mean f-score:', np.mean(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3373493975903614"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_binary = np.array([1 if x > 0 else 0 for x in pred.sum(axis=1)])\n",
    "len(pred_binary[np.where(pred_binary == 0)]) / len(pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining binary and multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred_mlc = []\n",
    "j = 0\n",
    "for i in range(len(comb_pred)):\n",
    "    if comb_pred[i] == 1:\n",
    "        comb_pred_mlc.append(pred[j])\n",
    "        j += 1\n",
    "    else:\n",
    "        comb_pred_mlc.append([0]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for binary class 1\n",
      "precision: 0.95\n",
      "recall: 0.58\n",
      "f-score: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Metric for binary class 1')\n",
    "pred_binary, prec_binary, rec_binary = binary_metric(df_test['negative_comments'], np.array(comb_pred_mlc))\n",
    "recap_binary_precision.append(prec_binary)\n",
    "recap_binary_recall.append(rec_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean precision: 0.75\n",
      "mean recall: 0.39\n",
      "mean f-score: 0.49\n"
     ]
    }
   ],
   "source": [
    "prec, rec, fs, _ = precision_recall_fscore_support(df_test[target_columns], comb_pred_mlc)\n",
    "print('mean precision: %.2f' % np.mean(prec))\n",
    "print('mean recall: %.2f' % np.mean(rec))\n",
    "print('mean f-score: %.2f' % np.mean(fs))\n",
    "recap_mean_precision.append(prec)\n",
    "recap_mean_recall.append(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5805855161787365,\n",
       " 0.5805855161787365,\n",
       " 0.6761171032357473,\n",
       " 0.749768875192604,\n",
       " 0.5805855161787365]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recap_binary_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3864441564578567,\n",
       " 0.3864441564578567,\n",
       " 0.49484002815232236,\n",
       " 0.5553101687900349,\n",
       " array([0.59869707, 0.26959248, 0.62514484, 0.14563107, 0.52075472,\n",
       "        0.15884477])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recap_mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
